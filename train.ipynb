{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T05:55:11.410724Z",
     "iopub.status.busy": "2020-12-02T05:55:11.410724Z",
     "iopub.status.idle": "2020-12-02T05:55:14.210013Z",
     "shell.execute_reply": "2020-12-02T05:55:14.209009Z",
     "shell.execute_reply.started": "2020-12-02T05:55:11.410724Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset bookcorpus (C:\\Users\\tmuds\\.cache\\huggingface\\datasets\\bookcorpus\\plain_text\\1.0.0\\af844be26c089fb64810e9f2cd841954fd8bd596d6ddd26326e4c70e2b8c96fc)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "dataset = load_dataset('bookcorpus', split='train')\n",
    "dataset.set_format('pandas', ['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TRAIN TOKENIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T13:34:45.115872Z",
     "iopub.status.busy": "2020-11-22T13:34:45.115872Z",
     "iopub.status.idle": "2020-11-22T13:40:46.054026Z",
     "shell.execute_reply": "2020-11-22T13:40:46.053547Z",
     "shell.execute_reply.started": "2020-11-22T13:34:45.115872Z"
    }
   },
   "outputs": [],
   "source": [
    "from tokenizers.implementations import BertWordPieceTokenizer, ByteLevelBPETokenizer\n",
    "\n",
    "# Initialize a tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer(lowercase=True)\n",
    "\n",
    "# Customize training\n",
    "tokenizer.train(files='bookcorpus.txt', vocab_size=50000, min_frequency=2, special_tokens=['<s>', '<pad>', '</s>', '<unk>', '<mask>'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T13:46:50.766467Z",
     "iopub.status.busy": "2020-11-22T13:46:50.766467Z",
     "iopub.status.idle": "2020-11-22T13:46:50.813340Z",
     "shell.execute_reply": "2020-11-22T13:46:50.812343Z",
     "shell.execute_reply.started": "2020-11-22T13:46:50.766467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BonzLM\\\\vocab.json', 'BonzLM\\\\merges.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_model(\"BonzLM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. INIT LANGUAGE MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T05:55:16.703375Z",
     "iopub.status.busy": "2020-12-02T05:55:16.703375Z",
     "iopub.status.idle": "2020-12-02T05:55:16.738281Z",
     "shell.execute_reply": "2020-12-02T05:55:16.737283Z",
     "shell.execute_reply.started": "2020-12-02T05:55:16.703375Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, RobertaTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('./tokenzier/WordPiece-10k/', max_len=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T05:55:18.155823Z",
     "iopub.status.busy": "2020-12-02T05:55:18.155823Z",
     "iopub.status.idle": "2020-12-02T05:55:18.165755Z",
     "shell.execute_reply": "2020-12-02T05:55:18.164758Z",
     "shell.execute_reply.started": "2020-12-02T05:55:18.155823Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def create_position_ids_from_input_ids(input_ids, padding_idx):\n",
    "    \"\"\"\n",
    "    Replace non-padding symbols with their position numbers. Position numbers begin at padding_idx+1. Padding symbols\n",
    "    are ignored. This is modified from fairseq's `utils.make_positions`.\n",
    "\n",
    "    Args:\n",
    "        x: torch.Tensor x:\n",
    "\n",
    "    Returns: torch.Tensor\n",
    "    \"\"\"\n",
    "    # The series of casts and type-conversions here are carefully balanced to both work with ONNX export and XLA.\n",
    "    mask = input_ids.ne(padding_idx).int()\n",
    "    incremental_indices = torch.cumsum(mask, dim=1).type_as(mask) * mask\n",
    "    return incremental_indices.long() + padding_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformer Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T05:55:20.504241Z",
     "iopub.status.busy": "2020-12-02T05:55:20.504241Z",
     "iopub.status.idle": "2020-12-02T05:55:20.525181Z",
     "shell.execute_reply": "2020-12-02T05:55:20.524183Z",
     "shell.execute_reply.started": "2020-12-02T05:55:20.504241Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReformerConfig {\n",
       "  \"attention_head_size\": 64,\n",
       "  \"attn_layers\": [\n",
       "    \"local\",\n",
       "    \"lsh\",\n",
       "    \"local\",\n",
       "    \"lsh\",\n",
       "    \"local\",\n",
       "    \"lsh\"\n",
       "  ],\n",
       "  \"axial_norm_std\": 1.0,\n",
       "  \"axial_pos_embds\": true,\n",
       "  \"axial_pos_embds_dim\": [\n",
       "    64,\n",
       "    64\n",
       "  ],\n",
       "  \"axial_pos_shape\": [\n",
       "    16,\n",
       "    16\n",
       "  ],\n",
       "  \"bos_token_id\": 2,\n",
       "  \"chunk_size_lm_head\": 0,\n",
       "  \"eos_token_id\": 3,\n",
       "  \"feed_forward_size\": 512,\n",
       "  \"feed_foward_size\": 512,\n",
       "  \"hash_seed\": null,\n",
       "  \"hidden_act\": \"relu\",\n",
       "  \"hidden_dropout_prob\": 0.05,\n",
       "  \"hidden_size\": 128,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"local_attention_probs_dropout_prob\": 0.05,\n",
       "  \"local_attn_chunk_length\": 32,\n",
       "  \"local_num_chunks_after\": 0,\n",
       "  \"local_num_chunks_before\": 1,\n",
       "  \"lsh_attention_probs_dropout_prob\": 0.0,\n",
       "  \"lsh_attn_chunk_length\": 32,\n",
       "  \"lsh_num_chunks_after\": 0,\n",
       "  \"lsh_num_chunks_before\": 1,\n",
       "  \"max_position_embeddings\": 256,\n",
       "  \"model_type\": \"reformer\",\n",
       "  \"num_attention_heads\": 6,\n",
       "  \"num_buckets\": 8,\n",
       "  \"num_hashes\": 4,\n",
       "  \"num_hidden_layers\": 6,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"vocab_size\": 10000\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ReformerConfig\n",
    "\n",
    "config = ReformerConfig(attention_head_size=64,\n",
    "                        num_attention_heads=6,\n",
    "                        num_hidden_layers=6,\n",
    "                        num_buckets=8,\n",
    "                        num_hashes=4,\n",
    "                        axial_pos_embds_dim=[64, 64],\n",
    "                        hidden_size=128,\n",
    "                        axial_pos_shape=[16, 16],\n",
    "                        max_position_embeddings= 256,\n",
    "                        bos_token_id=2,\n",
    "                        eos_token_id=3,\n",
    "                        pad_token_id=0,\n",
    "                        feed_foward_size=512,\n",
    "                        hash_seed=None,\n",
    "                        local_attn_chunk_length=32,\n",
    "                        lsh_attn_chunk_length=32,\n",
    "                        vocab_size=tokenizer.vocab_size\n",
    "                       )\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Reformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T05:55:22.492178Z",
     "iopub.status.busy": "2020-12-02T05:55:22.492178Z",
     "iopub.status.idle": "2020-12-02T05:55:22.594986Z",
     "shell.execute_reply": "2020-12-02T05:55:22.593990Z",
     "shell.execute_reply.started": "2020-12-02T05:55:22.492178Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5678096"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ReformerForMaskedLM\n",
    "\n",
    "model = ReformerForMaskedLM(config=config)\n",
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2020-11-21T18:50:32.523462Z",
     "iopub.status.busy": "2020-11-21T18:50:32.523462Z",
     "iopub.status.idle": "2020-11-21T18:50:39.129799Z",
     "shell.execute_reply": "2020-11-21T18:50:39.128802Z",
     "shell.execute_reply.started": "2020-11-21T18:50:32.523462Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-cea0a3c7ccc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbenchmark_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPyTorchBenchmarkArguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence_lengths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Reformer\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_process\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mbenchmark\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPyTorchBenchmark\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_config\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbenchmark_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\benchmark\\benchmark_utils.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    696\u001b[0m                             \u001b[0minference_result_memory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"result\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspeed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 698\u001b[1;33m                             \u001b[0mtime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference_speed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    699\u001b[0m                             \u001b[0minference_result_time\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"result\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\benchmark\\benchmark_utils.py\u001b[0m in \u001b[0;36minference_speed\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minference_speed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mseparate_process_wrapper_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inference_speed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_multi_processing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_speed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\benchmark\\benchmark.py\u001b[0m in \u001b[0;36m_inference_speed\u001b[1;34m(self, model_name, batch_size, sequence_length)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_inference_speed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0m_inference\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_inference_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_measure_speed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_inference\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     def _inference_memory(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\benchmark\\benchmark.py\u001b[0m in \u001b[0;36m_measure_speed\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m                 \u001b[0mrepeat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m                 \u001b[0mnumber\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m             )\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\timeit.py\u001b[0m in \u001b[0;36mrepeat\u001b[1;34m(stmt, setup, timer, repeat, number, globals)\u001b[0m\n\u001b[0;32m    235\u001b[0m            repeat=default_repeat, number=default_number, globals=None):\n\u001b[0;32m    236\u001b[0m     \u001b[1;34m\"\"\"Convenience function to create Timer object and call repeat method.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mTimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstmt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msetup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_wrap_timer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\timeit.py\u001b[0m in \u001b[0;36mrepeat\u001b[1;34m(self, repeat, number)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\timeit.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m             \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\timeit.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(_it, _timer, _stmt)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\benchmark\\benchmark.py\u001b[0m in \u001b[0;36mencoder_forward\u001b[1;34m()\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mencoder_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minference_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_reformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, num_hashes, past_buckets_states, use_cache, output_hidden_states, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m   2088\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2089\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2090\u001b[1;33m             \u001b[0mstart_idx_pos_encodings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_idx_pos_encodings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2091\u001b[0m         )\n\u001b[0;32m   2092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_reformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, position_ids, inputs_embeds, start_idx_pos_encodings)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[1;31m# add positional embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[0mposition_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membeddings\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_reformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, position_ids)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 [\n\u001b[0;32m    200\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition_encodings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m                 ],\n\u001b[0;32m    203\u001b[0m                 \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_reformer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 [\n\u001b[0;32m    200\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition_encodings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m                 ],\n\u001b[0;32m    203\u001b[0m                 \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import PyTorchBenchmarkArguments, PyTorchBenchmark\n",
    "\n",
    "new_config = config\n",
    "new_config.num_buckets = 16\n",
    "benchmark_args = PyTorchBenchmarkArguments(sequence_lengths=[256], batch_sizes=[16,32,64,128,256,512,1024], models=[\"Reformer\"], multi_process=False)\n",
    "benchmark = PyTorchBenchmark(configs=[new_config], args=benchmark_args,)\n",
    "result = benchmark.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T05:55:27.869109Z",
     "iopub.status.busy": "2020-12-02T05:55:27.869109Z",
     "iopub.status.idle": "2020-12-02T05:56:28.885606Z",
     "shell.execute_reply": "2020-12-02T05:56:28.885606Z",
     "shell.execute_reply.started": "2020-12-02T05:55:27.869109Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('bookcorpus.txt', names=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T05:56:28.888599Z",
     "iopub.status.busy": "2020-12-02T05:56:28.888599Z",
     "iopub.status.idle": "2020-12-02T05:56:29.269583Z",
     "shell.execute_reply": "2020-12-02T05:56:29.263596Z",
     "shell.execute_reply.started": "2020-12-02T05:56:28.888599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   2, 1476, 2530,   17, 6739, 2491, 1633, 1497, 1476, 2497, 1495, 3121,\n",
       "        3204, 8052, 4837, 7228, 1506, 1015, 1577, 2201, 6235, 1011, 7559, 7185,\n",
       "        7228, 1506, 1015, 1577, 2201, 6235, 1011, 1597, 5411, 8684,   18, 1547,\n",
       "        1027, 1010,   30, 3668, 1033, 1042, 1033, 9398, 1044, 1034, 1032, 1547,\n",
       "        1027, 1010,   17, 3601,   30,   29, 8568,   17, 3668, 1033, 1042, 1033,\n",
       "        9398, 1044, 1034, 1034, 1533, 1559, 2411,   16, 1684, 9343, 1550, 1484,\n",
       "        1896, 2399, 4396, 1533, 1559, 4712, 2365,   21, 4602, 9564, 1013, 3543,\n",
       "        1484, 1501, 2645,   16, 1814,   35,   51, 3310,   51, 1561,   43, 2228,\n",
       "        2860, 1484, 1521, 2573,   18, 3338, 2102, 1013,   16, 1901, 4838, 1547,\n",
       "        1563, 1476, 2093, 1502, 1018, 3194, 1903, 1484, 3222,   18, 1968,   43,\n",
       "        2161, 2802, 2909,   16, 1476, 2321, 1839, 2476, 3365, 1649, 2338,   18,\n",
       "        1968,   43, 2093, 1839, 1649, 3075, 2547, 1014, 1778, 2247, 1638, 1502,\n",
       "        4415, 1599, 3182, 4287, 1623, 1541, 1649, 2625,   18, 1777, 1909, 2476,\n",
       "        2034, 1577, 3119,   16, 1577, 1639, 1028, 1017,   18, 1575, 1742, 1014,\n",
       "        1686, 1476, 2530, 1495, 1512,   18, 1565,   51, 1567,   18,   51, 1686,\n",
       "        1512, 1597, 1489, 3338, 2102, 1013, 1547, 1563, 1476, 2093, 1839, 1502,\n",
       "        1728, 1484, 1501, 1795, 2185,   18, 1476, 1777, 2607, 1925, 1612, 1633,\n",
       "        3365, 1581, 1547, 1909, 4996,   16, 6371,   16, 6780, 1489,   51, 1589,\n",
       "        2745, 1512, 1521, 1774,   18,   51, 2347, 2415, 1476, 3517, 2851, 2727,\n",
       "          16, 7748, 7801, 1484, 5077, 3590, 1517, 7843, 1013,   18,    3,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class BonzDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        super(BonzDataset, self).__init__()\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = self.tokenizer.encode(self.df['text'][idx], padding='max_length', truncation=True, return_tensors='pt').squeeze(0)\n",
    "        for i in range(1,1000):\n",
    "            concated_text = ' '.join(df['text'][idx: idx+i+1].tolist())\n",
    "            temp = self.tokenizer.encode(concated_text, padding='max_length', truncation=True, return_tensors='pt').squeeze(0)\n",
    "            if temp[-1] == self.tokenizer.pad_token_id:\n",
    "                input_ids = temp\n",
    "            else:\n",
    "                break\n",
    "        return input_ids\n",
    "\n",
    "dataset = BonzDataset(df, tokenizer)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining DataCollator & Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T05:56:38.463057Z",
     "iopub.status.busy": "2020-12-02T05:56:38.463057Z",
     "iopub.status.idle": "2020-12-02T05:56:38.476023Z",
     "shell.execute_reply": "2020-12-02T05:56:38.475025Z",
     "shell.execute_reply.started": "2020-12-02T05:56:38.463057Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T06:00:38.389199Z",
     "iopub.status.busy": "2020-12-02T06:00:38.389199Z",
     "iopub.status.idle": "2020-12-02T06:00:38.412085Z",
     "shell.execute_reply": "2020-12-02T06:00:38.411087Z",
     "shell.execute_reply.started": "2020-12-02T06:00:38.389199Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "MAX_STEP = (100000 * 256) // BATCH_SIZE\n",
    "WARMUP_STEP = (MAX_STEP*0.05) // 1\n",
    "LEARNING_RATE = 5e-5\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./BonzLM\",\n",
    "    overwrite_output_dir=True,\n",
    "    # Training step\n",
    "    max_steps=MAX_STEP,\n",
    "    warmup_steps=WARMUP_STEP,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    save_steps=10000,\n",
    "    save_total_limit=2,\n",
    "    # mixed precision\n",
    "    fp16=True,\n",
    "    fp16_opt_level='O2',\n",
    "    seed=42,\n",
    "    # Learning rate setup\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.001,\n",
    "    adam_beta2=0.98,\n",
    "    adam_epsilon=1e-6,\n",
    "    max_grad_norm=0,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T06:17:54.567125Z",
     "iopub.status.busy": "2020-12-02T06:17:54.567125Z",
     "iopub.status.idle": "2020-12-02T06:18:01.185880Z",
     "shell.execute_reply": "2020-12-02T06:18:01.185880Z",
     "shell.execute_reply.started": "2020-12-02T06:17:54.567125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2, 1565, 9268, 3283, 4379, 1589, 6638, 1899, 1764, 3438, 1532, 1680,\n",
      "         2267, 2791, 1489, 1589, 5690, 2121, 1612, 3555, 1541, 1476, 2485, 1495,\n",
      "         1680, 3863,   18, 9414, 1523, 1575, 1619, 1612, 1722,   43, 5854, 2342,\n",
      "         1684, 1547, 5465, 1961, 1764, 2485,   18, 1521, 1547, 1649, 3013, 2410,\n",
      "           16, 2120, 4004, 2160, 1480, 2757,   16, 1489, 1512, 9527, 2603, 1591,\n",
      "         1816, 3467, 1502, 1728, 1484, 1936, 1551, 1512,   18, 2663,   16, 1502,\n",
      "         1489,   51, 1619, 4501, 1484, 7667, 1816, 3287, 1683, 2197, 1476, 3438,\n",
      "           18, 1502, 1589, 1896, 1710, 1577, 4687, 1496, 1830, 1484, 2770, 3035,\n",
      "         1532, 1476, 5396, 1025, 1495, 1581, 3438,   18, 2938, 1502, 1489, 1649,\n",
      "         2198, 1589, 1710, 7083, 1484, 1476, 9268, 3283, 1016, 5396, 1025, 1013,\n",
      "         1497, 8298, 1495, 1597, 1476, 2290, 2077, 1525, 1489, 2487, 1760, 1734,\n",
      "         1653, 1652,   18, 1517, 1476, 1782, 1720,   16,   51, 1754,   43, 2227,\n",
      "         1045, 1684, 1547, 3759, 2102, 1517, 1476, 4374, 2994,   18, 1476, 3926,\n",
      "         1495, 1559, 1902, 1497, 1581, 3920, 1489, 3261, 1497, 3350, 3920, 1013,\n",
      "         1547, 2505,   18, 2092,   16, 1960, 3759, 2102, 1865, 3679,   16, 1502,\n",
      "         3206, 3855, 4373, 1816, 7157, 1649, 3110,   18, 1512, 1547, 5948, 3684,\n",
      "         1484, 1501, 8872, 1591, 1652,   18,   51, 5857, 7420, 1666, 3518, 2601,\n",
      "         2822, 1015, 1489, 3759, 1801, 1484, 1592, 1007, 1484, 7013, 1890, 9083,\n",
      "         3062, 1666, 1652,   18, 1632, 1502, 1577, 7495, 1653, 1652, 1521, 1502,\n",
      "         1858, 1575, 2107, 1633, 1825, 5396, 1701, 1476, 3438,   35, 1956, 1007,\n",
      "         1035, 1900,   18,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   42,   42, 1879, 1501, 3684,   35, 1879, 1501, 3684,   35,   11,\n",
      "           11, 8424, 2852, 1993, 1551, 1476, 7487, 5665, 1497, 1524, 6595,   11,\n",
      "           61, 2170,   18,   42,   42, 8424,   16, 1638, 1581, 2142, 7555, 1502,\n",
      "           16, 1638, 1512, 7465, 1599, 1595, 1502, 1619,   16, 1512, 1683, 2263,\n",
      "         1502,    5,   11,   11,   42,   42, 8083,   11,   11,   42,   42, 1567,\n",
      "           56,   11,   62, 1502, 8083, 1550,   18, 1502, 1706, 1598, 1979, 4033,\n",
      "         1489, 1706, 1649, 6425, 6866,   16, 1726,    5,   51, 1589, 2742, 1559,\n",
      "         3574,   16, 1559, 3532,   16, 1489, 1559, 2683,   17, 1497,   17, 2718,\n",
      "         1484, 1982, 9394,    5,   51, 1683, 1563, 4171, 1559, 2903, 6329, 2601,\n",
      "         1009, 1556,    5,   11,   11, 8424,   11,   61, 2205, 4112, 1479, 1533,\n",
      "         1524, 1489, 1476, 4667, 1488, 1521, 1538,   11,   46, 5781,   16, 1565,\n",
      "         1538, 1651,   56,   11,   62, 1661, 1717,   18,   42,   42, 1502, 1626,\n",
      "           56,   11,   62, 2438, 1638, 1512, 1632, 1502, 8083,   18, 1844, 1495,\n",
      "         1597, 1495, 1476, 6099, 1837, 1521, 1683, 4171, 1680, 3261, 1638, 1545,\n",
      "         1567,   18,   11,   11, 1524, 6595,   11,   61, 1822, 6399, 3622, 1533,\n",
      "           43, 3792, 2200, 1781, 1538, 5151, 1524, 2563, 2941, 1517, 8424, 1756,\n",
      "           18,   42,   42,   51, 2006, 1541, 1502,   18,   51, 2006, 6099,   11,\n",
      "           61, 2149, 1695,   18,   11,   11,   43, 4672, 5512, 1497, 8424,   11,\n",
      "           61, 2919,   18, 1538, 1651,   56,   11,   62, 7591, 1541, 1521,   18,\n",
      "            3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]])\n"
     ]
    }
   ],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=torch.utils.data.RandomSampler(dataset))\n",
    "for a in data_loader:\n",
    "    print(a)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T06:16:10.937953Z",
     "iopub.status.busy": "2020-12-02T06:16:10.937953Z",
     "iopub.status.idle": "2020-12-02T06:16:17.653096Z",
     "shell.execute_reply": "2020-12-02T06:16:17.653096Z",
     "shell.execute_reply.started": "2020-12-02T06:16:10.937953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   2,   51, 1561, 1476,    4, 1521, 1512, 1561,    4,   11,   62,    4,\n",
       "          1727, 1865, 2274,   51,   11,   46, 5745, 2392, 1579,    4, 1512, 1516,\n",
       "          2623, 4166, 1551, 1476,    4,   17,    4,   51, 3321,    4, 1529, 2103,\n",
       "          1589, 5957, 1521, 1499, 1706, 1692, 2611,   18,    4,    4, 7164, 1025,\n",
       "          1516, 5776, 1484, 1501,    4,   18, 7794,    4, 4031, 2594, 4022, 1476,\n",
       "          7406,   18,    4,   43, 2200,   16,   51, 3522, 1925, 1499,    4, 4649,\n",
       "          1517,    4, 2515,   17, 1781,   51, 3938, 1521,   51,   11,   46, 7579,\n",
       "          1497, 1764, 2210,   18, 2821, 7794, 1647,   56,   11,   62,    4, 1728,\n",
       "          1484, 3655, 1717,    4,    4, 2210, 2727,   18,   42,   42, 1502, 1629,\n",
       "          1502, 2135, 1484, 1501, 1541, 1579,   16,    4,    4,   11,   11,    4,\n",
       "          1606, 1629,   18,   42,   42, 1577,   16, 1567, 1512,    4,   11,   11,\n",
       "          1674, 1659,    4,   16, 7794, 1489,   51, 1632, 1497, 1476, 3476, 8810,\n",
       "          1015, 1497, 1754,    4, 1525,    4, 2727, 1497, 1476, 8225, 1944, 1839,\n",
       "             4, 4720, 4675, 1013, 1632, 2745,   18, 1499,    4, 6007, 2102, 1517,\n",
       "          1476, 2515,   16, 3125, 1543, 5867, 3674, 7904, 4720, 4675, 1497, 1535,\n",
       "          2097,   18,   43, 1923, 1014, 9424, 2541, 1517,    4,    4, 8667,   42,\n",
       "            42, 7794,   35,   11,   11,   51, 1629,   18, 1499, 1856, 1598,   16,\n",
       "          1489,    4,    4,    4, 5553, 6046, 1544,    4,    4, 1489, 2379,   18,\n",
       "            42,   42, 4287, 1492,    4,   35, 1502,   11, 1527, 1810,    4, 4347,\n",
       "            11,   42,   42, 2724,   16, 1565,    4, 1839,   11,   61, 1810,   35,\n",
       "            11,    4, 7794, 3468, 1476, 2491, 1489, 9917, 1550, 1497,    4, 6898,\n",
       "            18,    3,    0,    0],\n",
       "         [   2,    4,    4,   18, 1612,   18, 1968, 4793, 1492,   18, 7497, 2915,\n",
       "          1014, 1810,   18, 1847, 1839, 1476, 1499, 1678, 1547, 1538,   35, 8809,\n",
       "          1589, 1612, 2640,   18, 1645,   51, 1983, 4090, 1476, 5635, 8325,    4,\n",
       "          2033, 1512, 1868, 2197,   35, 1900, 4008,   18, 1512, 1516, 1896, 4406,\n",
       "          1588, 1775, 1938, 1796,    4, 1521, 1013,    4, 1502, 2235,   18, 1499,\n",
       "          2757,    4, 7497, 6791, 1979, 1577,   51, 1850, 1501,    4, 1484, 1983,\n",
       "            18, 4008, 1651, 1735, 1476, 5901, 5514, 2153, 4280, 1484, 2021,    4,\n",
       "             4, 1808,    4, 8324, 1013,    4, 1680, 3970, 1010, 1562,   18, 1545,\n",
       "             4, 1484, 2197,   18, 1538, 4067,   18,    4, 5269, 2031, 1489, 2587,\n",
       "          2575, 1476, 8325, 3981,    4, 3151, 2399, 1652,   18,    4, 1633, 1495,\n",
       "          1476,    4, 1684,    4, 1551, 1476, 4563, 1489, 3463,    4,    4, 2048,\n",
       "          1599, 3681,   18, 2197,    5, 1476, 3479, 5680, 3215, 5981, 1013, 1792,\n",
       "          1014, 1936, 3646,   16, 1634, 1516,    4, 1707, 1484, 7591, 1666, 1595,\n",
       "          1516, 1476, 1814, 3991,   18, 1575, 2587, 1717,    4, 4033,    4,    4,\n",
       "             4, 4563,    4, 4008, 1856, 1551,    4, 2760, 1489, 2129, 1512, 8068,\n",
       "          1717, 1484,    4, 2300, 1495, 7066,   18, 4793, 1492,   16, 1619, 1502,\n",
       "          1868,    4,   35, 1638, 1502, 1619, 1695,    4, 1813,    4, 1484, 3563,\n",
       "          1643,    4, 4471, 1591, 4179, 5343, 3141, 1484, 2647, 1014,    4,    4,\n",
       "          1476,    4, 5200, 1506, 1015, 2877,   18, 1645, 1502, 2455, 1550,   35,\n",
       "          1634, 1516, 1612,    4,   18, 4793, 1492,   35, 4067, 4008,   18, 1538,\n",
       "          1856, 1551,    4, 2760, 1489, 2129, 1521,    4, 2760,    4, 1516, 2616,\n",
       "             4,    3,    0,    0]]),\n",
       " 'labels': tensor([[-100, -100, -100, -100, 2830, -100, -100, -100,   56, -100, -100, 1710,\n",
       "          -100, -100, -100, -100, -100, -100, 2051, -100, -100,   17, -100, -100,\n",
       "          -100, -100, 1551, -100, 7796, -100, 1565, -100, -100, 8373, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, 3588, 6086, -100, -100,\n",
       "          -100, -100, -100, -100, 2392, -100, -100, 9659, -100, -100, -100, -100,\n",
       "          -100, -100, 1533, -100, -100, -100, -100, -100, -100, -100, 1516, -100,\n",
       "          -100, 1476, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3453,\n",
       "          -100, -100, -100, -100, 2623, -100, -100, -100, -100, -100, 1778, -100,\n",
       "          -100, -100, -100, 1517, 1521, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, 1814,   35, -100, -100, 3885,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100,   18, -100, -100,\n",
       "          -100, -100, 1521, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, 1617, -100,   16, -100, -100, -100, -100, -100, -100,\n",
       "          1476, -100, -100, -100, -100, -100, -100, -100, 1516, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, 3674, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, 1476, 4917,   18, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, 1535, 1822, 1632, -100, -100, -100, 1541, 4742, -100, -100, -100,\n",
       "          -100, -100, -100, -100, 4925, -100, -100, -100, -100, 1810,   35,   11,\n",
       "          -100, -100, -100, -100, -100, -100,   17, -100, -100, -100, -100, -100,\n",
       "          -100,   11, -100, -100, -100, -100, -100, -100, -100, -100, 1535, -100,\n",
       "          -100, -100, -100, -100],\n",
       "         [-100, 1538, 1900, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1545,\n",
       "          -100, -100, -100, -100, -100, -100, 1983,   35, -100, 5635, -100,   18,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, 1638, -100, -100, 1595, -100, -100, -100, -100,\n",
       "          -100,   18, -100, -100, 1550, -100, -100, -100, -100, 2498, -100, 1983,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1680,\n",
       "          1774, -100, 1476, -100, -100, 1497, -100, -100, -100, -100, -100, -100,\n",
       "          1589, -100, -100, -100, -100, -100, -100, 1476, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100,   18, -100, -100, -100, -100, 1629, -100, -100,\n",
       "          -100, 3215, -100, 4415, -100, -100, -100, -100, -100, 1535, 2873, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, 1661, -100, -100, -100, 1612, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, 1476, -100, 1669, 1476,\n",
       "          2847, -100,   18, -100, -100, -100, 1524, -100, -100, -100, -100, -100,\n",
       "          -100, -100, 1633, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, 1634, -100, -100, -100, -100, -100,   51, -100, 1502, -100, -100,\n",
       "          -100, 1476, -100, -100, -100, -100, -100, -100, -100, -100, 5974, 1517,\n",
       "          -100, 4948, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, 1516, -100, 4942, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, 1524, -100, -100, -100, -100, 1524, -100, 7066, -100, -100,\n",
       "            18, -100, -100, -100]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datalodaer = trainer.get_train_dataloader()\n",
    "for a in train_datalodaer:\n",
    "    break\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T05:58:00.793065Z",
     "iopub.status.busy": "2020-12-02T05:58:00.793065Z",
     "iopub.status.idle": "2020-12-02T05:58:00.812970Z",
     "shell.execute_reply": "2020-12-02T05:58:00.811973Z",
     "shell.execute_reply.started": "2020-12-02T05:58:00.793065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:50:19.283993Z",
     "iopub.status.busy": "2020-11-26T05:50:19.283993Z",
     "iopub.status.idle": "2020-11-30T04:23:29.381634Z",
     "shell.execute_reply": "2020-11-30T04:23:29.380635Z",
     "shell.execute_reply.started": "2020-11-26T05:50:19.283993Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "./BonzLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: duyduc1110 (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.10.11 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.5<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">./BonzLM</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/duyduc1110/huggingface\" target=\"_blank\">https://wandb.ai/duyduc1110/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/duyduc1110/huggingface/runs/32d869x2\" target=\"_blank\">https://wandb.ai/duyduc1110/huggingface/runs/32d869x2</a><br/>\n",
       "                Run data is saved locally in <code>wandb\\run-20201126_135020-32d869x2</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmuds\\miniconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:114: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='100000' max='100000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100000/100000 94:32:56, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>9.264078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>9.264594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>9.264578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>9.264437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>9.264188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>9.264375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>9.264391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>9.264297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>9.264188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>9.264328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>9.264359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>9.264281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>9.264203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>9.264422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>9.264016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>9.264234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>9.264047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>9.264016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>9.264297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>9.264297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>9.264047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>9.264047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>9.264141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>9.264391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>9.264266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>9.264359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>9.264188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>9.264188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>9.264031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>9.263844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>9.263531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>9.264094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>9.263250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>9.263875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>9.264250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>9.263938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>9.263969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>9.264156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>9.264219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>9.263813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>9.263625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>9.263625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>9.263750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>9.263781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>9.263844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>9.263531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>9.263531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>9.263938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>9.263844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>9.263906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>9.263656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>9.264156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>9.263781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>9.263438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>9.263500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>9.263875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>9.259250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>9.251500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>9.251250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>9.250750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>9.251625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>9.252250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>9.251375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>9.252375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>9.251000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>9.251750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>9.251750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>9.251125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>9.251375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>9.251625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>9.251875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>9.251375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>9.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>9.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>9.251625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>9.251750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>9.251875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>9.251125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>9.251625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>9.251687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>9.251312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>9.251812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>9.251062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>9.250875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>9.251375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>9.251000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43500</td>\n",
       "      <td>9.251750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>9.252250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44500</td>\n",
       "      <td>9.251375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>9.251125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45500</td>\n",
       "      <td>9.251750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>9.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46500</td>\n",
       "      <td>9.251625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>9.251125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47500</td>\n",
       "      <td>9.251875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>9.251125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48500</td>\n",
       "      <td>9.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>9.251563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49500</td>\n",
       "      <td>9.251312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>9.250500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50500</td>\n",
       "      <td>9.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>9.251125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51500</td>\n",
       "      <td>9.251125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>9.251750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52500</td>\n",
       "      <td>9.251625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>9.251625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53500</td>\n",
       "      <td>9.251375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>9.251375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54500</td>\n",
       "      <td>9.251500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>9.251125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55500</td>\n",
       "      <td>9.251000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>9.251250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56500</td>\n",
       "      <td>9.251125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>9.250750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Wall time: 3d 22h 33min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100000, training_loss=9.2543975)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T06:23:24.948494Z",
     "iopub.status.busy": "2020-12-01T06:23:24.948494Z",
     "iopub.status.idle": "2020-12-01T06:23:25.037222Z",
     "shell.execute_reply": "2020-12-01T06:23:25.035227Z",
     "shell.execute_reply.started": "2020-12-01T06:23:24.948494Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model('test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T05:14:53.882297Z",
     "iopub.status.busy": "2020-11-24T05:14:53.882297Z",
     "iopub.status.idle": "2020-11-24T05:14:53.897256Z",
     "shell.execute_reply": "2020-11-24T05:14:53.896258Z",
     "shell.execute_reply.started": "2020-11-24T05:14:53.882297Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. TEST MODEL WITH MASK TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T05:27:34.149647Z",
     "iopub.status.busy": "2020-11-24T05:27:34.149647Z",
     "iopub.status.idle": "2020-11-24T05:27:34.673187Z",
     "shell.execute_reply": "2020-11-24T05:27:34.673187Z",
     "shell.execute_reply.started": "2020-11-24T05:27:34.149647Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fill_mask = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=\"./test2\",\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T05:28:14.045852Z",
     "iopub.status.busy": "2020-11-24T05:28:14.045852Z",
     "iopub.status.idle": "2020-11-24T05:28:14.078762Z",
     "shell.execute_reply": "2020-11-24T05:28:14.077781Z",
     "shell.execute_reply.started": "2020-11-24T05:28:14.045852Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': '<s>Today is a`` day.</s>',\n",
       "  'score': 0.2213928997516632,\n",
       "  'token': 308,\n",
       "  'token_str': '``'},\n",
       " {'sequence': '<s>Today is a very day.</s>',\n",
       "  'score': 0.0527605339884758,\n",
       "  'token': 832,\n",
       "  'token_str': 'very'},\n",
       " {'sequence': '<s>Today is athis day.</s>',\n",
       "  'score': 0.03341570124030113,\n",
       "  'token': 954,\n",
       "  'token_str': 'this'},\n",
       " {'sequence': '<s>Today is awhat day.</s>',\n",
       "  'score': 0.0221271850168705,\n",
       "  'token': 780,\n",
       "  'token_str': 'what'},\n",
       " {'sequence': '<s>Today is athe day.</s>',\n",
       "  'score': 0.01886608637869358,\n",
       "  'token': 350,\n",
       "  'token_str': 'the'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_mask(\"Today is a <mask> day.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T06:29:58.475591Z",
     "iopub.status.busy": "2020-11-24T06:29:58.475591Z",
     "iopub.status.idle": "2020-11-24T06:30:03.706788Z",
     "shell.execute_reply": "2020-11-24T06:30:03.702799Z",
     "shell.execute_reply.started": "2020-11-24T06:29:58.475591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=huggingface-demo\n",
      "env: GLUE_DIR=glue_data\n",
      "env: TASK_NAME=MRPC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/24/2020 14:30:01 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "11/24/2020 14:30:01 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='/tmp/$TASK_NAME/', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=0.0002, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs\\\\Nov24_14-30-01_DS3', logging_first_step=False, logging_steps=50, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=50, dataloader_num_workers=0, past_index=-1, run_name='/tmp/$TASK_NAME/', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
      "Reusing dataset glue (C:\\Users\\tmuds\\.cache\\huggingface\\datasets\\glue\\mrpc\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "[INFO|configuration_utils.py:411] 2020-11-24 14:30:03,415 >> loading configuration file ./test2\\config.json\n",
      "[INFO|configuration_utils.py:449] 2020-11-24 14:30:03,416 >> Model config ReformerConfig {\n",
      "  \"architectures\": [\n",
      "    \"ReformerForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_head_size\": 64,\n",
      "  \"attn_layers\": [\n",
      "    \"local\",\n",
      "    \"lsh\",\n",
      "    \"local\",\n",
      "    \"lsh\",\n",
      "    \"local\",\n",
      "    \"lsh\"\n",
      "  ],\n",
      "  \"axial_norm_std\": 1.0,\n",
      "  \"axial_pos_embds\": true,\n",
      "  \"axial_pos_embds_dim\": [\n",
      "    64,\n",
      "    64\n",
      "  ],\n",
      "  \"axial_pos_shape\": [\n",
      "    16,\n",
      "    16\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"chunk_size_lm_head\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feed_forward_size\": 512,\n",
      "  \"feed_foward_size\": 512,\n",
      "  \"finetuning_task\": \"mrpc\",\n",
      "  \"hash_seed\": null,\n",
      "  \"hidden_act\": \"relu\",\n",
      "  \"hidden_dropout_prob\": 0.05,\n",
      "  \"hidden_size\": 128,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"local_attention_probs_dropout_prob\": 0.05,\n",
      "  \"local_attn_chunk_length\": 32,\n",
      "  \"local_num_chunks_after\": 0,\n",
      "  \"local_num_chunks_before\": 1,\n",
      "  \"lsh_attention_probs_dropout_prob\": 0.0,\n",
      "  \"lsh_attn_chunk_length\": 32,\n",
      "  \"lsh_num_chunks_after\": 0,\n",
      "  \"lsh_num_chunks_before\": 1,\n",
      "  \"max_position_embeddings\": 256,\n",
      "  \"model_type\": \"reformer\",\n",
      "  \"num_attention_heads\": 6,\n",
      "  \"num_buckets\": 16,\n",
      "  \"num_hashes\": 1,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"vocab_size\": 50000\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:411] 2020-11-24 14:30:03,418 >> loading configuration file ./test2\\config.json\n",
      "[INFO|configuration_utils.py:449] 2020-11-24 14:30:03,419 >> Model config ReformerConfig {\n",
      "  \"architectures\": [\n",
      "    \"ReformerForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_head_size\": 64,\n",
      "  \"attn_layers\": [\n",
      "    \"local\",\n",
      "    \"lsh\",\n",
      "    \"local\",\n",
      "    \"lsh\",\n",
      "    \"local\",\n",
      "    \"lsh\"\n",
      "  ],\n",
      "  \"axial_norm_std\": 1.0,\n",
      "  \"axial_pos_embds\": true,\n",
      "  \"axial_pos_embds_dim\": [\n",
      "    64,\n",
      "    64\n",
      "  ],\n",
      "  \"axial_pos_shape\": [\n",
      "    16,\n",
      "    16\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"chunk_size_lm_head\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feed_forward_size\": 512,\n",
      "  \"feed_foward_size\": 512,\n",
      "  \"hash_seed\": null,\n",
      "  \"hidden_act\": \"relu\",\n",
      "  \"hidden_dropout_prob\": 0.05,\n",
      "  \"hidden_size\": 128,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"local_attention_probs_dropout_prob\": 0.05,\n",
      "  \"local_attn_chunk_length\": 32,\n",
      "  \"local_num_chunks_after\": 0,\n",
      "  \"local_num_chunks_before\": 1,\n",
      "  \"lsh_attention_probs_dropout_prob\": 0.0,\n",
      "  \"lsh_attn_chunk_length\": 32,\n",
      "  \"lsh_num_chunks_after\": 0,\n",
      "  \"lsh_num_chunks_before\": 1,\n",
      "  \"max_position_embeddings\": 256,\n",
      "  \"model_type\": \"reformer\",\n",
      "  \"num_attention_heads\": 6,\n",
      "  \"num_buckets\": 16,\n",
      "  \"num_hashes\": 1,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"vocab_size\": 50000\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1577] 2020-11-24 14:30:03,419 >> Model name './test2' not found in model shortcut name list (google/reformer-crime-and-punishment). Assuming './test2' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "[INFO|tokenization_utils_base.py:1607] 2020-11-24 14:30:03,420 >> Didn't find file ./test2\\spiece.model. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1607] 2020-11-24 14:30:03,420 >> Didn't find file ./test2\\tokenizer.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1607] 2020-11-24 14:30:03,420 >> Didn't find file ./test2\\added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1648] 2020-11-24 14:30:03,421 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1648] 2020-11-24 14:30:03,421 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1648] 2020-11-24 14:30:03,421 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1648] 2020-11-24 14:30:03,421 >> loading file ./test2\\special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1648] 2020-11-24 14:30:03,422 >> loading file ./test2\\tokenizer_config.json\n",
      "Traceback (most recent call last):\n",
      "  File \"run_glue.py\", line 418, in <module>\n",
      "    main()\n",
      "  File \"run_glue.py\", line 242, in main\n",
      "    use_fast=model_args.use_fast_tokenizer,\n",
      "  File \"C:\\Users\\tmuds\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\tokenization_auto.py\", line 339, in from_pretrained\n",
      "    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)\n",
      "  File \"C:\\Users\\tmuds\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\tokenization_utils_base.py\", line 1653, in from_pretrained\n",
      "    resolved_vocab_files, pretrained_model_name_or_path, init_configuration, *init_inputs, **kwargs\n",
      "  File \"C:\\Users\\tmuds\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\tokenization_utils_base.py\", line 1671, in _from_pretrained\n",
      "    **(copy.deepcopy(kwargs)),\n",
      "  File \"C:\\Users\\tmuds\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\tokenization_utils_base.py\", line 1725, in _from_pretrained\n",
      "    tokenizer = cls(*init_inputs, **init_kwargs)\n",
      "  File \"C:\\Users\\tmuds\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\tokenization_reformer.py\", line 99, in __init__\n",
      "    self.sp_model.Load(vocab_file)\n",
      "  File \"C:\\Users\\tmuds\\miniconda3\\lib\\site-packages\\sentencepiece.py\", line 367, in Load\n",
      "    return self.LoadFromFile(model_file)\n",
      "  File \"C:\\Users\\tmuds\\miniconda3\\lib\\site-packages\\sentencepiece.py\", line 177, in LoadFromFile\n",
      "    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self, arg)\n",
      "TypeError: not a string\n",
      "11/24/2020 14:30:03 - INFO - wandb.internal.internal -   Internal process exited\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT=huggingface-demo\n",
    "%env GLUE_DIR=glue_data\n",
    "%env TASK_NAME=MRPC\n",
    "\n",
    "!python run_glue.py \\\n",
    "  --model_name_or_path ./test2 \\\n",
    "  --task_name MRPC \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --max_seq_length 256 \\\n",
    "  --per_device_train_batch_size 32 \\\n",
    "  --learning_rate 2e-4 \\\n",
    "  --num_train_epochs 3 \\\n",
    "  --output_dir /tmp/$TASK_NAME/ \\\n",
    "  --overwrite_output_dir \\\n",
    "  --logging_steps 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T06:29:04.709924Z",
     "iopub.status.busy": "2020-11-24T06:29:04.709924Z",
     "iopub.status.idle": "2020-11-24T06:29:04.873757Z",
     "shell.execute_reply": "2020-11-24T06:29:04.872715Z",
     "shell.execute_reply.started": "2020-11-24T06:29:04.709924Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained('./test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T06:29:34.184206Z",
     "iopub.status.busy": "2020-11-24T06:29:34.183210Z",
     "iopub.status.idle": "2020-11-24T06:29:34.296584Z",
     "shell.execute_reply": "2020-11-24T06:29:34.294589Z",
     "shell.execute_reply.started": "2020-11-24T06:29:34.183210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./test2\\\\tokenizer_config.json',\n",
       " './test2\\\\special_tokens_map.json',\n",
       " './test2\\\\vocab.json',\n",
       " './test2\\\\merges.txt',\n",
       " './test2\\\\added_tokens.json')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('./test2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
